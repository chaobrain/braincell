{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afbe60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import brainunit as u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aeb9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnionFind:\n",
    "    '''\n",
    "    Union-Find (Disjoint Set Union) data structure.\n",
    "\n",
    "    This data structure efficiently manages disjoint sets and supports:\n",
    "      - find(x): returns the representative (root) of the set containing x\n",
    "      - union(x, y): merges the sets containing x and y\n",
    "\n",
    "    In the context of dendritic or cable models,\n",
    "    this is used to merge electrically equivalent (equipotential) points.\n",
    "    For example, if each segment is divided into three points (e.g., at 0, 0.5, 1),\n",
    "    and connections join two segment at certain positions,\n",
    "    those positions are physically the same node (equipotential) and should be merged.\n",
    "\n",
    "    Path compression is used to flatten the structure for fast queries.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> uf = UnionFind()\n",
    "    >>> uf.union(0, 1)\n",
    "    >>> uf.union(2, 3)\n",
    "    >>> uf.union(1, 2)\n",
    "    >>> uf.find(0)\n",
    "    0\n",
    "    >>> uf.find(3)\n",
    "    0\n",
    "    >>> uf.find(4)\n",
    "    4\n",
    "\n",
    "    After these operations:\n",
    "      - Elements 0, 1, 2, 3 are in the same set with representative 0.\n",
    "      - Element 4 remains in its own set.\n",
    "\n",
    "    In a dendritic tree,\n",
    "    using union(segA_pos, segB_pos) will ensure that the two physically identical points\n",
    "    are treated as a single equipotential node in subsequent calculations.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rep = {}\n",
    "\n",
    "    def find(self, x):\n",
    "        '''\n",
    "        Finds the representative (\"root\") of the set containing x.\n",
    "        Uses path compression: after calling find(x), self.rep[x] will point directly to the root.\n",
    "        '''\n",
    "        if x not in self.rep:\n",
    "            self.rep[x] = x\n",
    "        if self.rep[x] != x:\n",
    "            self.rep[x] = self.find(self.rep[x])\n",
    "        return self.rep[x]\n",
    "\n",
    "    def union(self, x, y):\n",
    "        '''\n",
    "        Merges the sets containing x and y.\n",
    "        After union, x and y will have the same representative.\n",
    "        '''\n",
    "        self.rep[self.find(y)] = self.find(x)\n",
    "\n",
    "def nodeid(seg, pos):\n",
    "    '''\n",
    "    Assign a unique integer ID to a position on a segment.\n",
    "\n",
    "    In this scheme, each segment is discretized into three key points:\n",
    "      - 0   (start)\n",
    "      - 0.5 (center)\n",
    "      - 1   (end)\n",
    "\n",
    "    The global node ID is computed so that each (seg, pos) pair maps to a unique integer.\n",
    "    This is useful for algorithms (such as Union-Find) that need to quickly check or merge\n",
    "    equipotential nodes at connections.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    seg : int\n",
    "        Segment index.\n",
    "    pos : float\n",
    "        Position on the segment (must be 0, 0.5, or 1).\n",
    "\n",
    "    Returns\n",
    "\n",
    "    int\n",
    "        Unique node ID for this (segment, position).\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> nodeid(0, 0)\n",
    "    0\n",
    "    >>> nodeid(0, 0.5)\n",
    "    1\n",
    "    >>> nodeid(0, 1)\n",
    "    2\n",
    "    >>> nodeid(1, 0)\n",
    "    3\n",
    "    >>> nodeid(1, 0.5)\n",
    "    4\n",
    "    >>> nodeid(2, 1)\n",
    "    8\n",
    "    '''\n",
    "    return seg * 3 + {0: 0, 0.5: 1, 1: 2}[pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddcf50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_equipotential_segment_nodes(num_segments, parent_id, parentx):\n",
    "    '''\n",
    "    Use Union-Find to merge equipotential nodes at segment connections.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_segments : int\n",
    "        Number of segments.\n",
    "    parent_id : list of int\n",
    "        For each segment, index of its parent segment (-1 for root).\n",
    "    parentx : list of float\n",
    "        For each segment, the position on the parent segment where the connection is made (e.g., 0, 0.5, or 1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    uf : UnionFind\n",
    "        The UnionFind structure after merging all equipotential nodes.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    For each segment with a parent, this merges the parent's connection position with the 0-point of the child segment.\n",
    "    The UnionFind structure is then used to map each node ID to its merged representative.\n",
    "    '''\n",
    "    uf = UnionFind()\n",
    "    for seg in range(num_segments):\n",
    "        if parent_id[seg] != -1:\n",
    "            parent = parent_id[seg]\n",
    "            px = parentx[seg]\n",
    "            uf.union(nodeid(parent, px), nodeid(seg, 0))\n",
    "    return uf\n",
    "\n",
    "\n",
    "def build_segment_internal_edges(num_segments):\n",
    "    '''\n",
    "    Create the edges representing internal connectivity within each segment.\n",
    "    Each segment is discretized into three points, connected as: 0 -- 0.5 -- 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_segments : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    edges : list of tuple of int\n",
    "        Each tuple is (node_id_a, node_id_b), representing a directed edge from node_id_a to node_id_b.\n",
    "    '''\n",
    "    edges = []\n",
    "    for seg in range(num_segments):\n",
    "        n0 = nodeid(seg, 0)\n",
    "        n05 = nodeid(seg, 0.5)\n",
    "        n1 = nodeid(seg, 1)\n",
    "        edges += [(n0, n05), (n05, n1)]\n",
    "    return edges\n",
    "\n",
    "\n",
    "def get_merged_edges(edges, uf):\n",
    "    '''\n",
    "    Apply Union-Find merging to the internal segment edges,\n",
    "    producing a list of merged (representative) node edges, eliminating self-loops.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edges : list of tuple of int\n",
    "        List of original (node_a, node_b) edges.\n",
    "    uf : UnionFind\n",
    "        The UnionFind structure containing merged node mappings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    merged_edges : list of tuple of int\n",
    "        List of merged node edges (no self-loops).\n",
    "    '''\n",
    "    merged_edges = []\n",
    "    for a, b in edges:\n",
    "        ma, mb = uf.find(a), uf.find(b)\n",
    "        if ma != mb:\n",
    "            merged_edges.append((ma, mb))\n",
    "    return merged_edges\n",
    "\n",
    "\n",
    "def build_segment_graph(merged_edges):\n",
    "    '''\n",
    "    Construct a directed graph from the merged segment edges using NetworkX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    merged_edges : list of tuple of int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    G : nx.DiGraph\n",
    "        The directed graph of the merged segment structure.\n",
    "    '''\n",
    "    import networkx as nx\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(merged_edges)\n",
    "    return G\n",
    "\n",
    "\n",
    "def classify_segment_nodes(num_segments, uf, G):\n",
    "    '''\n",
    "    Classify merged nodes as segment centers, non-center non-leaf, or leaf nodes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_segments : int\n",
    "        Number of segments.\n",
    "    uf : UnionFind\n",
    "        UnionFind structure with merged node IDs.\n",
    "    G : nx.DiGraph\n",
    "        Directed graph of merged structure.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    center_ids : set of int\n",
    "        Set of merged node IDs corresponding to all segment centers (0.5 position).\n",
    "    leaf_ids : list of int\n",
    "        List of merged node IDs that are leaf nodes (degree 1, not a center).\n",
    "    noncenter_nonleaf_ids : list of int\n",
    "        List of merged node IDs that are neither centers nor leaves.\n",
    "    '''\n",
    "    segid_to_center = {seg: uf.find(nodeid(seg, 0.5)) for seg in range(num_segments)}\n",
    "    center_ids = set(segid_to_center.values())\n",
    "    leaf_ids = [n for n in G.nodes if G.degree[n] == 1 and n not in center_ids]\n",
    "    noncenter_nonleaf_ids = [n for n in G.nodes if n not in center_ids and n not in leaf_ids]\n",
    "    return center_ids, leaf_ids, noncenter_nonleaf_ids\n",
    "\n",
    "\n",
    "def build_segment_node_labels(num_segments, uf):\n",
    "    '''\n",
    "    Build string labels for each merged node for visualization.\n",
    "    All equivalent points (after merging) are grouped.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_segments : int\n",
    "    uf : UnionFind\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    node_labels : dict\n",
    "        Key: merged node ID, Value: concatenated label string (one per merged node).\n",
    "    label_groups : dict\n",
    "        Key: merged node ID, Value: set of original labels.\n",
    "    '''\n",
    "    label_groups = {}\n",
    "    for seg in range(num_segments):\n",
    "        for pos in [0, 0.5, 1]:\n",
    "            nid = uf.find(nodeid(seg, pos))\n",
    "            label = f\"seg{seg}({pos:.1f})\"\n",
    "            label_groups.setdefault(nid, set()).add(label)\n",
    "    node_labels = {nid: \"\\n\".join(sorted(labels)) for nid, labels in label_groups.items()}\n",
    "    return node_labels, label_groups\n",
    "\n",
    "\n",
    "def build_half_segment_maps(num_segments, uf):\n",
    "    '''\n",
    "    Construct lookup tables for \"half-segments\" (connections between points within each segment).\n",
    "    This is useful for assigning resistances or mapping between merged nodes and physical segment halves.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_segments : int\n",
    "    uf : UnionFind\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nid_half_map : dict\n",
    "        Key: (minid, maxid) tuple of merged node IDs, Value: (segment index, '0-0.5' or '0.5-1')\n",
    "    node2halves : dict\n",
    "        Key: merged node ID, Value: set of (segment index, which_half) tuples\n",
    "    '''\n",
    "    nid_half_map = dict()\n",
    "    node2halves = dict()\n",
    "    for seg in range(num_segments):\n",
    "        nid0 = uf.find(nodeid(seg, 0))\n",
    "        nid05 = uf.find(nodeid(seg, 0.5))\n",
    "        nid1 = uf.find(nodeid(seg, 1))\n",
    "        for pair, half in [((nid0, nid05), '0-0.5'), ((nid05, nid1), '0.5-1')]:\n",
    "            pair_sorted = tuple(sorted(pair))\n",
    "            nid_half_map[pair_sorted] = (seg, half)\n",
    "            for n in pair:\n",
    "                node2halves.setdefault(n, set()).add((seg, half))\n",
    "    return nid_half_map, node2halves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f545f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dhs_group_by_depth(depths_sorted, max_group_size):\n",
    "    \"\"\"\n",
    "    Group row indices by node depth, from deepest (bottom) to shallowest (root),\n",
    "    ensuring each group contains only nodes at the same depth and does not exceed max_group_size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    depths_sorted : list of int\n",
    "        List of node depths, sorted according to the matrix row order.\n",
    "    max_group_size : int\n",
    "        Maximum allowed size for each group.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    groups : list of list of int\n",
    "        Each sublist contains row indices grouped together at the same depth.\n",
    "    \"\"\"\n",
    "    n = len(depths_sorted)\n",
    "    groups = []\n",
    "    i = n - 1\n",
    "    while i >= 0:\n",
    "        group_depth = depths_sorted[i]\n",
    "        group = []\n",
    "        # Group together nodes at the same depth, up to max_group_size\n",
    "        while i >= 0 and depths_sorted[i] == group_depth and len(group) < max_group_size:\n",
    "            group.append(i)\n",
    "            i -= 1\n",
    "        groups.append(sorted(group))\n",
    "    groups.reverse()\n",
    "    return groups\n",
    "\n",
    "\n",
    "def tree_layout(G, root=None, dx=1.5, dy=1.7):\n",
    "    \"\"\"\n",
    "    Compute a simple layered (tree-like) layout for a directed graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.DiGraph\n",
    "        Directed graph representing the tree.\n",
    "    root : int, optional\n",
    "        Node id of the root; defaults to the node with in-degree zero.\n",
    "    dx : float\n",
    "        Horizontal spacing between nodes.\n",
    "    dy : float\n",
    "        Vertical spacing between levels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pos : dict\n",
    "        Dictionary mapping node id to (x, y) coordinates.\n",
    "    \"\"\"\n",
    "    if root is None:\n",
    "        root = [n for n in G.nodes if G.in_degree(n) == 0][0]\n",
    "    pos = {}\n",
    "    width = [0]  # Horizontal position accumulator\n",
    "\n",
    "    def dfs(node, depth):\n",
    "        children = list(G.successors(node))\n",
    "        if not children:\n",
    "            pos[node] = (width[0], -depth * dy)\n",
    "            width[0] += dx\n",
    "        else:\n",
    "            xs = []\n",
    "            for c in children:\n",
    "                dfs(c, depth + 1)\n",
    "                xs.append(pos[c][0])\n",
    "            pos[node] = (sum(xs) / len(xs), -depth * dy)\n",
    "    dfs(root, 0)\n",
    "    return pos\n",
    "\n",
    "\n",
    "def plot_tree(G, node_labels, center_ids, noncenter_nonleaf_ids, leaf_ids, root=None):\n",
    "    \"\"\"\n",
    "    Plot a layered tree structure with nodes colored by category.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.DiGraph\n",
    "        The graph to plot.\n",
    "    node_labels : dict\n",
    "        Node id -> label string.\n",
    "    center_ids, noncenter_nonleaf_ids, leaf_ids : list or set\n",
    "        Lists/sets of node ids for each node type (center, non-center non-leaf, leaf).\n",
    "    root : int, optional\n",
    "        Node id to use as the root for layout.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import networkx as nx\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    color_map = {}\n",
    "    for nid in G.nodes:\n",
    "        if nid in center_ids:\n",
    "            color_map[nid] = 'cornflowerblue'\n",
    "        elif nid in noncenter_nonleaf_ids:\n",
    "            color_map[nid] = 'gold'\n",
    "        elif nid in leaf_ids:\n",
    "            color_map[nid] = 'limegreen'\n",
    "        else:\n",
    "            color_map[nid] = 'gray'\n",
    "    node_colors = [color_map[nid] for nid in G.nodes]\n",
    "    pos = tree_layout(G, root)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, #labels=node_labels, \n",
    "            node_size=100, font_size=4, font_color='black', edge_color='gray', arrowsize=18)\n",
    "    legend_items = [\n",
    "        mpatches.Patch(color='cornflowerblue', label='Segment Center Node'),\n",
    "        mpatches.Patch(color='gold', label='Non-leaf Non-center Node'),\n",
    "        mpatches.Patch(color='limegreen', label='Leaf Node')\n",
    "    ]\n",
    "    plt.legend(handles=legend_items, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.title('Tree Structure Node Classification (Layered)')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def make_branching_tree_parent_id(L=3, n_branches=2, n_levels=3):\n",
    "    \"\"\"\n",
    "    Generate a parent_id array for a branching tree structure.\n",
    "    Each chain has length L, each branch splits into n_branches, repeated for n_levels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    L : int\n",
    "        Length of each straight chain segment before branching.\n",
    "    n_branches : int\n",
    "        Number of branches at each branch point.\n",
    "    n_levels : int\n",
    "        Number of branching levels from root to leaves.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    parent_id : list of int\n",
    "        parent_id[i] gives the parent segment id for segment i (-1 for root).\n",
    "    \"\"\"\n",
    "    parent_id = [-1]\n",
    "    node_id = 0\n",
    "    frontier = [0]\n",
    "    for level in range(n_levels):\n",
    "        new_frontier = []\n",
    "        for src in frontier:\n",
    "            chain_start = src\n",
    "            for i in range(L - 1):\n",
    "                node_id += 1\n",
    "                parent_id.append(chain_start)\n",
    "                chain_start = node_id\n",
    "            for j in range(n_branches):\n",
    "                node_id += 1\n",
    "                parent_id.append(chain_start)\n",
    "                new_frontier.append(node_id)\n",
    "        frontier = new_frontier\n",
    "    return parent_id\n",
    "\n",
    "def dhs_lower_triangularize(A, b, parent_rows):\n",
    "    \"\"\"\n",
    "    Perform in-place back-substitution elimination on matrix A and vector b from deepest node to root,\n",
    "    using the parent row index array (rowid2parentrowid, -1 means root).\n",
    "    This transforms A into lower-triangular form suitable for efficient forward substitution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray, shape (n, n)\n",
    "        System matrix. Should be ordered such that parent rows precede their children (e.g. depth order).\n",
    "    b : ndarray, shape (n,)\n",
    "        Right-hand side vector.\n",
    "    parent_rows : list or ndarray of int\n",
    "        For each row (0 ~ n-1), the parent's row index in A (use -1 for root).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A, b : tuple of ndarray\n",
    "        The modified matrix and vector after elimination (lower-triangular form).\n",
    "    \"\"\"\n",
    "    n = len(parent_rows)\n",
    "    for i in reversed(range(n)):\n",
    "        parent_row = parent_rows[i]\n",
    "        if parent_row != -1 and A[parent_row, i] != 0:\n",
    "            f = A[parent_row, i] / A[i, i]\n",
    "            A[parent_row, :] -= f * A[i, :]\n",
    "            b[parent_row] -= f * b[i]\n",
    "    return A, b\n",
    "\n",
    "def dhs_back_substitute_lower(A, b, parent_rows):\n",
    "    \"\"\"\n",
    "    Solve a lower-triangular system resulting from DHS elimination,\n",
    "    using the parent row index array (rowid2parentrowid).\n",
    "\n",
    "    This performs a forward substitution, assuming A has already been reduced\n",
    "    to lower-triangular form (i.e., each node depends only on itself and its parent).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray, shape (n, n)\n",
    "        Lower-triangular matrix after elimination.\n",
    "    b : ndarray, shape (n,)\n",
    "        Right-hand side vector.\n",
    "    parent_rows : list or ndarray of int\n",
    "        For each row (0 ~ n-1), the parent's row index in A (use -1 for root).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : ndarray, shape (n,)\n",
    "        Solution vector, with x[i] corresponding to row i (same order as input).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    n = len(parent_rows)\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        s = b[i]\n",
    "        parent_row = parent_rows[i]\n",
    "        if parent_row != -1:\n",
    "            s -= A[i, parent_row] * x[parent_row]\n",
    "        x[i] = s / A[i, i]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d395863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conductance_matrix(G, nid_half_map, seg_resistances):\n",
    "    \"\"\"\n",
    "    Construct the conductance matrix Gmat for all nodes in the graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.DiGraph\n",
    "        Directed graph of the dendritic/cable tree.\n",
    "    nid_half_map : dict\n",
    "        Maps node pairs (tuple) to (segment id, '0-0.5' or '0.5-1').\n",
    "    seg_resistances : list of tuple\n",
    "        Segment resistance for each segment: [(R0-0.5, R0.5-1), ...]\n",
    "    unit : physical unit, optional\n",
    "        Unit to apply at the end, e.g., u.siemens\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Gmat : np.ndarray (optionally with unit)\n",
    "        Symmetric axial conductance matrix of shape (n, n).\n",
    "    nodes : list\n",
    "        List of node ids corresponding to rows/cols of Gmat.\n",
    "    \"\"\"\n",
    "    nodes = sorted(G.nodes)\n",
    "    n = len(nodes)\n",
    "    Gmat = np.zeros((n, n), dtype=float)\n",
    "\n",
    "    for i, nid_i in enumerate(nodes):\n",
    "        for j, nid_j in enumerate(nodes):\n",
    "            if i >= j:\n",
    "                continue\n",
    "            pair = tuple(sorted([nid_i, nid_j]))\n",
    "            if pair in nid_half_map:\n",
    "                sec, which_half = nid_half_map[pair]\n",
    "                if which_half == '0-0.5':\n",
    "                    resistance = float(seg_resistances[sec][0])  # 保证为标量\n",
    "                elif which_half == '0.5-1':\n",
    "                    resistance = float(seg_resistances[sec][1])\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected segment half '{which_half}' for pair {pair}\")\n",
    "                g = 1.0 / resistance\n",
    "                Gmat[i, j] = g\n",
    "                Gmat[j, i] = g\n",
    "\n",
    "    np.fill_diagonal(Gmat, -Gmat.sum(axis=1))\n",
    "    return Gmat, nodes\n",
    "\n",
    "def get_root_and_depths(G):\n",
    "    \"\"\"\n",
    "    Identify the root node and compute node depths (distance from root).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.DiGraph\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    root : node id\n",
    "    depths : dict\n",
    "        node id -> depth (distance from root)\n",
    "    \"\"\"\n",
    "    root = [n for n in G.nodes if G.in_degree(n) == 0][0]\n",
    "    depths = nx.single_source_shortest_path_length(G, root)\n",
    "    return root, depths\n",
    "\n",
    "def sort_nodes_by_depth(G, depths):\n",
    "    \"\"\"\n",
    "    Sort all nodes in G by their depth (root to deepest).\n",
    "    Nodes unreachable from root will be placed at the end (with inf depth).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sorted_nodes : list\n",
    "        List of node ids sorted by depth.\n",
    "    \"\"\"\n",
    "    all_nodes = sorted(G.nodes)\n",
    "    sorted_nodes = sorted(all_nodes, key=lambda nid: depths.get(nid, np.inf))\n",
    "    return sorted_nodes\n",
    "\n",
    "def reorder_matrix_by_depth(mat, nodes, sorted_nodes):\n",
    "    \"\"\"\n",
    "    Reorder the resistance matrix according to depth order.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mat_sorted : ndarray\n",
    "    new_order : list\n",
    "        List of row indices for reordering.\n",
    "    \"\"\"\n",
    "    node_id2idx = {nid: idx for idx, nid in enumerate(nodes)}\n",
    "    new_order = [node_id2idx[nid] for nid in sorted_nodes]\n",
    "    print(new_order)\n",
    "    mat_sorted = mat[np.ix_(new_order, new_order)]\n",
    "    return mat_sorted\n",
    "\n",
    "def get_depths_sorted(depths, sorted_nodes):\n",
    "    \"\"\"\n",
    "    Generate a list of depths ordered by sorted_nodes.\n",
    "    \"\"\"\n",
    "    return [depths[nid] for nid in sorted_nodes]\n",
    "\n",
    "def build_parent_dict(G, root):\n",
    "    \"\"\"\n",
    "    Build a dict mapping each node to its parent, using BFS.\n",
    "    Root will not be present as a key.\n",
    "    \"\"\"\n",
    "    return dict(nx.bfs_predecessors(G, root))\n",
    "\n",
    "def get_depth_node_idx_map(sorted_nodes):\n",
    "    \"\"\"\n",
    "    Map node id to its row index in sorted_nodes.\n",
    "    \"\"\"\n",
    "    return {nid: idx for idx, nid in enumerate(sorted_nodes)}\n",
    "\n",
    "def get_parent_rows(sorted_nodes, parent_dict, node_id2rowid):\n",
    "    \"\"\"\n",
    "    For each row (i.e., each node in sorted_nodes), find its parent's row index.\n",
    "    If the node is a root, set parent index to -1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sorted_nodes : list\n",
    "        List of node ids, ordered as in the matrix/algorithm.\n",
    "    parent_dict : dict\n",
    "        Mapping from node id to its parent node id (as from BFS).\n",
    "    node_id2rowid : dict\n",
    "        Mapping from node id to row index in the sorted_nodes/matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    parent_rows : list of int\n",
    "        For each row index (0 ~ n-1), the parent's row index in matrix (or -1 for root).\n",
    "    \"\"\"\n",
    "    parent_rows = []\n",
    "    for i, nid in enumerate(sorted_nodes):\n",
    "        parent_id = parent_dict.get(nid, None)\n",
    "        if parent_id is not None:\n",
    "            parent_row = node_id2rowid[parent_id]\n",
    "        else:\n",
    "            parent_row = -1\n",
    "        parent_rows.append(parent_row)\n",
    "    return parent_rows\n",
    "\n",
    "def get_segment2rowid(num_segments, uf, sorted_nodes):\n",
    "    \"\"\"\n",
    "    Map each segment index (midpoint, 0.5) to its corresponding row index in Rmat_sorted.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_segments : int\n",
    "        Number of original segments.\n",
    "    uf : UnionFind\n",
    "        UnionFind structure after merging equipotential nodes.\n",
    "    sorted_nodes : list\n",
    "        Node ids in the row order of Rmat_sorted (length = number of physical nodes).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    segment2rowid : dict\n",
    "        Key: segment index (0-based), Value: row index in Rmat_sorted.\n",
    "    \"\"\"\n",
    "    # For each segment, find the merged node id at 0.5 (center)\n",
    "    segid_to_center_nid = {seg: uf.find(nodeid(seg, 0.5)) for seg in range(num_segments)}\n",
    "    # Map node id to row index in sorted_nodes (i.e., Rmat_sorted)\n",
    "    nid_to_rowid = {nid: rowid for rowid, nid in enumerate(sorted_nodes)}\n",
    "    # Build segment to row mapping\n",
    "    segment2rowid = {seg: nid_to_rowid[segid_to_center_nid[seg]] for seg in range(num_segments)}\n",
    "    return segment2rowid\n",
    "\n",
    "def build_uppers_lowers(Gmat, parent_rows):\n",
    "    n = len(parent_rows)\n",
    "    lowers = u.math.zeros(n) * u.get_unit(Gmat)\n",
    "    uppers = u.math.zeros(n) * u.get_unit(Gmat)\n",
    "    for i in range(n):\n",
    "        p = parent_rows[i]\n",
    "        if p == -1:\n",
    "            lowers = lowers.at[i].set(0 * u.get_unit(Gmat)) \n",
    "            uppers = uppers.at[i].set(0 * u.get_unit(Gmat))\n",
    "        else:\n",
    "            lowers = lowers.at[i].set(Gmat[i, p])\n",
    "            uppers = uppers.at[i].set(Gmat[p, i])\n",
    "    return lowers, uppers\n",
    "\n",
    "def build_flipped_comp_edges(dhs_group, parent_rows):\n",
    "    \"\"\"\n",
    "    Build flipped_comp_edges for DHS/Jaxley given groupings and parent_rows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dhs_group : list of list of int\n",
    "        Each sublist contains the row indices of nodes in a depth group.\n",
    "    parent_rows : array-like of int\n",
    "        For each row, its parent's row index (-1 for root).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    flipped_comp_edges : list of ndarray (n_group, 2)\n",
    "        Each element: array of [child_row, parent_row] for all pairs in that group.\n",
    "    \"\"\"\n",
    "    flipped_comp_edges = []\n",
    "    for group in dhs_group:\n",
    "        pairs = []\n",
    "        for child in group:\n",
    "            parent = parent_rows[child]\n",
    "            if parent != -1:    # skip root\n",
    "                pairs.append([child, parent])\n",
    "        if pairs:   # Only append if non-empty\n",
    "            flipped_comp_edges.append(np.array(pairs, dtype=int))\n",
    "    return flipped_comp_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1190a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_branching_tree(parent_id, parentx, seg_resistances, max_group_size=8, plot=False):\n",
    "    \"\"\"\n",
    "    Preprocess a branching tree for DHS matrix algorithms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent_id : list of int\n",
    "        For each segment, the parent segment index (-1 for root).\n",
    "    parentx : list\n",
    "        For each segment, the connection location on parent (not used here, but required for node merging).\n",
    "    seg_resistances : list of tuple\n",
    "        For each segment, (R_0-0.5, R_0.5-1).\n",
    "    max_group_size : int, optional\n",
    "        Max group size for DHS grouping (default 8).\n",
    "    plot : bool, optional\n",
    "        If True, visualize the classified segment tree.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Rmat_sorted : ndarray\n",
    "        The resistance matrix after depth-based reordering (n_nodes x n_nodes).\n",
    "    parent_rows : list of int\n",
    "        For each node (row in Rmat_sorted), the parent's row index (-1 for root).\n",
    "    sorted_nodes : list\n",
    "        Node ids in depth order (corresponds to row indices).\n",
    "    groups : list of list of int\n",
    "        Each sublist contains row indices (in Rmat_sorted) that form a group for parallel DHS.\n",
    "    segment2rowid : dict\n",
    "        Mapping: segment index (0-based) -> row index in Rmat_sorted (corresponds to segment center).\n",
    "    \"\"\"\n",
    "    # Step 1: Merge equipotential nodes at segment connections\n",
    "    num_segments = len(parent_id)\n",
    "    uf = merge_equipotential_segment_nodes(num_segments, parent_id, parentx)\n",
    "\n",
    "    # Step 2: Build internal edges and merged edges\n",
    "    edges = build_segment_internal_edges(num_segments)\n",
    "    merged_edges = get_merged_edges(edges, uf)\n",
    "\n",
    "    # Step 3: Build directed graph from merged node edges\n",
    "    G = build_segment_graph(merged_edges)\n",
    "\n",
    "    # Step 4: (Optional) Build node labels, classify, prepare for visualization\n",
    "    center_ids, leaf_ids, noncenter_nonleaf_ids = classify_segment_nodes(num_segments, uf, G)\n",
    "    print('center_id',center_ids)\n",
    "    node_labels, _ = build_segment_node_labels(num_segments, uf)\n",
    "    nid_half_map, _ = build_half_segment_maps(num_segments, uf)\n",
    "\n",
    "    if plot:\n",
    "        plot_tree(G, node_labels, center_ids, noncenter_nonleaf_ids, leaf_ids)\n",
    "\n",
    "    # Step 5: Construct conductance matrix and get list of all nodes\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    unit = u.get_unit(seg_resistances)\n",
    "    seg_resistances = u.get_magnitude(seg_resistances)\n",
    "    Gmat, nodes = build_conductance_matrix(G, nid_half_map, seg_resistances)\n",
    "    print('G cost',time.time()-t0)\n",
    "    # Step 6: Sort nodes by depth, reorder matrix \n",
    "    t0 = time.time()\n",
    "    root, depths = get_root_and_depths(G)\n",
    "    sorted_nodes = sort_nodes_by_depth(G, depths)\n",
    "    print(sorted_nodes)\n",
    "    Gmat_sorted = reorder_matrix_by_depth(Gmat, nodes, sorted_nodes) * (1/unit)\n",
    "    print('G sort cost',time.time()-t0)\n",
    "    # Step 7: Build parent row indices (rowid2parentrowid) for DHS elimination\n",
    "    parent_dict = build_parent_dict(G, root)\n",
    "    node_id2rowid = get_depth_node_idx_map(sorted_nodes)\n",
    "    parent_rows = get_parent_rows(sorted_nodes, parent_dict, node_id2rowid)\n",
    "\n",
    "    # Step 8: Group rows by depth (with max group size constraint)\n",
    "    depths_sorted = [depths[nid] for nid in sorted_nodes]\n",
    "    dhs_groups = dhs_group_by_depth(depths_sorted, max_group_size)\n",
    "\n",
    "    # Step 9: Map each segment center (0.5) to the corresponding row index in Rmat_sorted\n",
    "    segment2rowid = get_segment2rowid(num_segments, uf, sorted_nodes)\n",
    "\n",
    "    return Gmat_sorted, parent_rows, dhs_groups, segment2rowid\n",
    "\n",
    "def comp_based_triang(index, carry):\n",
    "    \"\"\"Triangulate the quasi-tridiagonal system compartment by compartment.\"\"\"\n",
    "    diags, solves, lowers, uppers, flipped_comp_edges = carry\n",
    "\n",
    "    # `flipped_comp_edges` has shape `(num_levels, num_comps_per_level, 2)`. We first\n",
    "    # get the relevant level with `[index]` and then we get all children and parents\n",
    "    # in the level.\n",
    "    comp_edge = flipped_comp_edges[index]\n",
    "\n",
    "    child = comp_edge[:, 0]\n",
    "    parent = comp_edge[:, 1]\n",
    "    print('c = ', child)\n",
    "    print('p = ', parent)\n",
    "    lower_val = lowers[child]\n",
    "    upper_val = uppers[child]\n",
    "    child_diag = diags[child]\n",
    "    child_solve = solves[child]\n",
    "\n",
    "    # Factor that the child row has to be multiplied by.\n",
    "    multiplier = upper_val / child_diag\n",
    "\n",
    "    # Updates to diagonal and solve\n",
    "    diags = diags.at[parent].add(-lower_val * multiplier)\n",
    "    solves = solves.at[parent].add(-child_solve * multiplier)\n",
    "\n",
    "    return (diags, solves, lowers, uppers, flipped_comp_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "741404a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_levels = 3; L = 1; n_branches = 2\n",
    "parent_id = make_branching_tree_parent_id(L, n_branches, n_levels)\n",
    "parentx = [-1] + (len(parent_id)-1)*[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c06925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 18:20:41.915165: W external/xla/xla/service/platform_util.cc:211] unable to create StreamExecutor for CUDA:7: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "seg_resistances = u.math.array(len(parent_id)*[(100* u.ohm,100* u.ohm)])\n",
    "unit = 1/u.get_unit(seg_resistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c40a80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center_id {1, 34, 4, 37, 7, 40, 10, 43, 13, 16, 19, 22, 25, 28, 31}\n",
      "G cost 0.2459123134613037\n",
      "[0, 1, 2, 4, 7, 5, 8, 10, 13, 16, 19, 11, 14, 17, 20, 22, 25, 28, 31, 34, 37, 40, 43, 23, 26, 29, 32, 35, 38, 41, 44]\n",
      "[0, 1, 2, 3, 5, 4, 6, 7, 9, 11, 13, 8, 10, 12, 14, 15, 17, 19, 21, 23, 25, 27, 29, 16, 18, 20, 22, 24, 26, 28, 30]\n",
      "G sort cost 0.0013132095336914062\n"
     ]
    }
   ],
   "source": [
    "Gmat_sorted, parent_rows, dhs_groups, segment2rowid  = preprocess_branching_tree(\n",
    "    parent_id, parentx, seg_resistances, max_group_size=8, plot=False\n",
    ")\n",
    "# generate uppers, lowers, diags and flipped_comp_edges\n",
    "lowers, uppers = build_uppers_lowers(Gmat_sorted, parent_rows)\n",
    "flipped_comp_edges = build_flipped_comp_edges(dhs_groups, parent_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braincell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
